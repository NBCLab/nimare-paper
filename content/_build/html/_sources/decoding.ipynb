{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add13f23",
   "metadata": {},
   "source": [
    "# Meta-Analytic Functional Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f0b8bd",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# First, import the necessary modules and functions\n",
    "import os\n",
    "\n",
    "from myst_nb import glue\n",
    "\n",
    "DATA_DIR = os.path.abspath(\"../data\")\n",
    "FIG_DIR = os.path.abspath(\"../images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc5e84d",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 features selected.\n"
     ]
    }
   ],
   "source": [
    "import nimare\n",
    "from nimare import meta\n",
    "\n",
    "dset_file = os.path.join(DATA_DIR, \"neurosynth_dataset_first500_with_mkda_ma.pkl.gz\")\n",
    "kern = meta.kernel.MKDAKernel(memory_limit=None)\n",
    "if not os.path.isfile(dset_file):\n",
    "    neurosynth_dset_first500 = nimare.dataset.Dataset.load(\n",
    "        os.path.join(DATA_DIR, \"neurosynth_dataset_first500.pkl.gz\")\n",
    "    )\n",
    "    target_folder = os.path.join(DATA_DIR, \"neurosynth_dataset_maps\")\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    neurosynth_dset_first500.update_path(target_folder)\n",
    "    neurosynth_dset_first500 = kern.transform(neurosynth_dset_first500, return_type=\"dataset\")\n",
    "    neurosynth_dset_first500.save(dset_file)\n",
    "else:\n",
    "    neurosynth_dset_first500 = nimare.dataset.Dataset.load(dset_file)\n",
    "\n",
    "# Collect features for decoding\n",
    "# We use any features that appear in >5% of studies and <95%.\n",
    "id_cols = [\"id\", \"study_id\", \"contrast_id\"]\n",
    "frequency_threshold = 0.001\n",
    "cols = neurosynth_dset_first500.annotations.columns\n",
    "cols = [c for c in cols if c not in id_cols]\n",
    "df = neurosynth_dset_first500.annotations.copy()[cols]\n",
    "n_studies = df.shape[0]\n",
    "feature_counts = (df >= frequency_threshold).sum(axis=0)\n",
    "target_features = feature_counts.between(n_studies * 0.05, n_studies * 0.95)\n",
    "target_features = target_features[target_features]\n",
    "target_features = target_features.index.values\n",
    "print(f\"{len(target_features)} features selected.\", flush=True)\n",
    "\n",
    "amygdala_roi = os.path.join(DATA_DIR, \"amygdala_roi.nii.gz\")\n",
    "amygdala_ids = neurosynth_dset_first500.get_studies_by_mask(amygdala_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec41ab",
   "metadata": {},
   "source": [
    "Functional decoding performed with meta-analytic data, refers to methods which attempt to predict mental states from neuroimaging data using a large-scale meta-analytic database {cite:p}`Smith2009-wk`.\n",
    "Such analyses may also be referred to as “informal reverse inference” {cite:p}`Poldrack2011-zp`, “functional characterization analysis” {cite:p}`Bzdok2013-gc,Cieslik2013-kz,Rottschy2013-cd`, “open-ended decoding” {cite:p}`Rubin2017-rd`, or simply “functional decoding” {cite:p}`Amft2015-kw,Bzdok2013-jv,Nickl-Jockschat2015-rg`.\n",
    "While the terminology is far from standardized, we will refer to this method as **meta-analytic functional decoding** in order to distinguish it from alternative methods like multivariate decoding and model-based decoding {cite:p}`Poldrack2011-zp`.\n",
    "Meta-analytic functional decoding is often used in conjunction with MACM, meta-analytic clustering, meta-analytic parcellation, and meta-ICA, in order to characterize resulting brain regions, clusters, or components.\n",
    "Meta-analytic functional decoding models have also been extended for the purpose of **meta-analytic functional encoding**, wherein text is used to generate statistical images {cite:p}`Dockes2018-ug,Nunes2018-du,Rubin2017-rd`.\n",
    "\n",
    "Four common approaches are correlation-based decoding, dot-product decoding, weight-sum decoding, and chi-square decoding.\n",
    "We will first discuss continuous decoding methods (i.e., correlation and dot-product), followed by discrete decoding methods (weight-sum and chi-square)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ffc11c",
   "metadata": {},
   "source": [
    "## Decoding continuous inputs\n",
    "\n",
    "When decoding unthresholded statistical maps, the most common approaches are to simply correlate the input map with maps from the database, or to compute the dot product between the two maps.\n",
    "In Neurosynth, meta-analyses are performed for each label (i.e., term or topic) in the database and then the input image is correlated with the resulting unthresholded statistical map from each meta-analysis.\n",
    "Performing statistical inference on the resulting correlations is not straightforward, however, as voxels display strong spatial correlations, and the true degrees of freedom are consequently unknown (and likely far smaller than the nominal number of voxels).\n",
    "In order to interpret the results of this decoding approach, users typically select some arbitrary number of top correlation coefficients ahead of time, and use the associated labels to describe the input map.\n",
    "However, such results should be interpreted with great caution.\n",
    "\n",
    "This approach can also be applied to an image-based database like NeuroVault, either by correlating input data with meta-analyzed statistical maps, or by deriving distributions of correlation coefficients by grouping statistical maps in the database according to label.\n",
    "Using these distributions, it is possible to statistically compare labels in order to assess label significance.\n",
    "NiMARE includes methods for both correlation-based decoding and correlation distribution-based decoding, although the correlation-based decoding is better established and should be preferred over the correlation distribution-based decoding.\n",
    "As such, we will only show the {py:class}`nimare.decode.continuous.CorrelationDecoder` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba53128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.decode.continuous:Decoding terms_abstract_tfidf__10 (0/283): 45/500 studies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.utils:Shared path detected: '/Users/taylor/Documents/nbc/nimare-paper/data/neurosynth_dataset_maps/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.utils:Shared path detected: '/Users/taylor/Documents/nbc/nimare-paper/data/neurosynth_dataset_maps/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:nimare.meta.cbma.mkda:_fit failed, removing None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:nimare.meta.cbma.mkda:_fit failed, removing None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File not found: '/Users/taylor/Documents/nbc/nimare-paper/data/neurosynth_dataset_maps/study-10356062-1_affine-34d2ff913320e14f04a4746cfa875fcd_memory_limit-None_r-10.0_value-1_MKDAKernel.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31935/2775975999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmemory_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcorr_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurosynth_dset_first500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mcorr_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"map_to_decode.nii.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nimare/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, drop_invalid)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_invalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_invalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nimare/decode/continuous.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mnonfeature_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mnonfeature_dset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonfeature_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonfeature_dset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nimare/meta/cbma/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset1, dataset2, drop_invalid)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"coordinates2\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coordinates\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"masker\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nimare/utils.py\u001b[0m in \u001b[0;36mmemmap_context\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nimare/meta/cbma/mkda.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset1, dataset2)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmaps_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ma_maps1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mcoords_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coordinates1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mfname_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m         ma_maps2 = self._collect_ma_maps(\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nimare/meta/cbma/base.py\u001b[0m in \u001b[0;36m_collect_ma_maps\u001b[0;34m(self, coords_key, maps_key, fname_idx)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 )\n\u001b[1;32m    167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mma_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaps_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mLGR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generating MA maps from coordinates ({coords_key}).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, imgs, confounds)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfounds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_variance_confounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_single_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# Compute high variance confounds if requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nilearn/input_data/nifti_masker.py\u001b[0m in \u001b[0;36mtransform_single_imgs\u001b[0;34m(self, imgs, confounds, copy)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mconfounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         )\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nilearn/input_data/nifti_masker.py\u001b[0m in \u001b[0;36mfilter_and_mask\u001b[0;34m(imgs, mask_img_, parameters, memory_level, memory, verbose, confounds, copy, dtype)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matleast_4d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Check whether resampling is truly necessary. If so, crop mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    278\u001b[0m             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n\u001b[1;32m    279\u001b[0m                                      dtype=dtype)\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mfirst_niimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot concatenate empty objects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/nimare-paper/conda_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/Users/taylor/Documents/nbc/nimare-paper/data/neurosynth_dataset_maps/study-10356062-1_affine-34d2ff913320e14f04a4746cfa875fcd_memory_limit-None_r-10.0_value-1_MKDAKernel.nii.gz'"
     ]
    }
   ],
   "source": [
    "from nimare import decode, meta\n",
    "\n",
    "corr_decoder = decode.continuous.CorrelationDecoder(\n",
    "    frequency_threshold=0.001,\n",
    "    meta_estimator=meta.MKDAChi2(kernel_transformer=kern, memory_limit=None),\n",
    "    target_image=\"z_desc-specificity\",\n",
    "    features=target_features,\n",
    "    memory_limit=None,\n",
    ")\n",
    "corr_decoder.fit(neurosynth_dset_first500)\n",
    "corr_df = corr_decoder.transform(os.path.join(DATA_DIR, \"map_to_decode.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf54f2",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "corr_df = corr_df.reindex(\n",
    "    corr_df[\"r\"].abs().sort_values(ascending=False).index\n",
    ")\n",
    "corr_df = corr_df.iloc[:10]\n",
    "glue(\"table_corr\", corr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33067d",
   "metadata": {},
   "source": [
    "```{glue:figure} table_corr\n",
    ":figwidth: 300px\n",
    ":name: \"tbl:table_corr\"\n",
    ":align: center\n",
    "\n",
    "The top ten terms, sorted by absolute correlation coefficient, from the correlation decoding method.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2eb1bf",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Here we delete the recent variables for the sake of reducing memory usage\n",
    "del corr_decoder, corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03324ec",
   "metadata": {},
   "source": [
    "## Decoding discrete inputs\n",
    "\n",
    "Decoding regions of interest requires a different approach than decoding unthresholded statistical maps.\n",
    "One simple approach, used by GCLDA and implemented in the function {py:func}`nimare.decode.discrete.gclda_decode_roi`, simply sums the `P(topic|voxel)` distribution across all voxels in the ROI in order to produce a value associated with each topic for the ROI.\n",
    "These **weight sum** values are arbitrarily scaled and cannot be compared across ROIs.\n",
    "\n",
    "One method which relies on correlations, much like the continuous correlation decoder, is the **ROI association** decoding method ({py:class}`nimare.decode.discete.ROIAssociationDecoder`), originally implemented in the Neurosynth Python library.\n",
    "In this method, each study with coordinates in the dataset is convolved with a kernel transformer to produce a modeled activation map.\n",
    "The resulting modeled activation maps are then masked with a region of interest (i.e., the target of the decoding), and the values are averaged within the ROI.\n",
    "These averaged modeled activation values are then correlated with the term weights for all labels in the dataset.\n",
    "This decoding method produces a single correlation coefficient for each of the dataset's labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_decoder = decode.discrete.ROIAssociationDecoder(\n",
    "    amygdala_roi,\n",
    "    u=0.05,\n",
    "    correction=\"fdr_bh\",\n",
    "    features=target_features,\n",
    ")\n",
    "assoc_decoder.fit(neurosynth_dset_first500)\n",
    "assoc_df = assoc_decoder.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99994e8",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "assoc_df = assoc_df.reindex(assoc_df[\"r\"].abs().sort_values(ascending=False).index)\n",
    "assoc_df = assoc_df.iloc[:10]\n",
    "glue(\"table_assoc\", assoc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817dddab",
   "metadata": {},
   "source": [
    "```{glue:figure} table_assoc\n",
    ":figwidth: 300px\n",
    ":name: \"tbl:table_assoc\"\n",
    ":align: center\n",
    "\n",
    "The top ten terms, sorted by absolute correlation coefficient, from the ROI association decoding method.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4890960",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Here we delete the recent variables for the sake of reducing memory usage\n",
    "del assoc_decoder, assoc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bd4bcd",
   "metadata": {},
   "source": [
    "A more theoretically driven approach to ROI decoding is to use **chi-square-based** methods.\n",
    "The two methods which use chi-squared tests are the BrainMap decoding method and an adaptation of Neurosynth’s meta-analysis method.\n",
    "\n",
    "In both chi-square-based methods, studies are first selected from a coordinate-based database according to some criterion.\n",
    "For example, if decoding a region of interest, users might select studies reporting at least one coordinate within 5 mm of the ROI.\n",
    "Metadata (such as ontological labels) for this subset of studies are then compared to those of the remaining, unselected portion of the database in a confusion matrix.\n",
    "For each label in the ontology, studies are divided into four groups: selected and label-positive (SS+L+), selected and label-negative (SS+L-), unselected and label-positive (SS-L+), and unselected and label-negative (SS-L-).\n",
    "Each method then compares these groups in order to evaluate both consistency and specificity of the relationship between the selection criteria and each label, which are evaluated in terms of both statistical significance and effect size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2007ee",
   "metadata": {},
   "source": [
    "### BrainMap method\n",
    "\n",
    "The BrainMap discrete decoding method, implemented in {py:class}`nimare.decode.discrete.BrainMapDecoder`, compares the distributions of studies with each label within the sample against those in a larger database while accounting for the number of foci from each study.\n",
    "Broadly speaking, this method assumes that the selection criterion is associated with one peak per study, which means that it is likely only appropriate for selection criteria based around foci, such as regions of interest.\n",
    "One common analysis, meta-analytic clustering, involves dividing studies within a database into meta-analytic groupings based on the spatial similarity of their modeled activation maps (i.e., study-wise pseudo-statistical maps produced by convolving coordinates with a kernel).\n",
    "The resulting sets of studies are often functionally decoded in order to build a functional profile associated with each meta-analytic grouping.\n",
    "While these groupings are defined as subsets of the database, they are not selected based on the location of an individual peak, and so weighting based on the number of foci would be inappropriate.\n",
    "\n",
    "This decoding method produces four outputs for each label.\n",
    "First, the distribution of studies in the sample with the label are compared to the distributions of other labels within the sample.\n",
    "This consistency analysis produces both a measure of statistical significance (i.e., a p-value) and a measure of effect size (i.e., the likelihood of being selected given the presence of the label).\n",
    "Next, the studies in the sample are compared to the studies in the rest of the database.\n",
    "This specificity analysis produces a p-value and an effect size measure of the posterior probability of having the label given selection into the sample.\n",
    "A detailed algorithm description is presented in **Appendix I**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "brainmap_decoder = decode.discrete.BrainMapDecoder(\n",
    "    frequency_threshold=0.001,\n",
    "    u=0.05,\n",
    "    correction=\"fdr_bh\",\n",
    "    features=target_features,\n",
    ")\n",
    "brainmap_decoder.fit(neurosynth_dset_first500)\n",
    "brainmap_df = brainmap_decoder.transform(amygdala_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e73bd",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "brainmap_df = brainmap_df.reindex(\n",
    "    brainmap_df[\"probReverse\"].abs().sort_values(ascending=False).index\n",
    ")\n",
    "brainmap_df = brainmap_df.iloc[:10]\n",
    "glue(\"table_brainmap\", brainmap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff98949",
   "metadata": {},
   "source": [
    "```{glue:figure} table_brainmap\n",
    ":figwidth: 300px\n",
    ":name: \"tbl:table_brainmap\"\n",
    ":align: center\n",
    "\n",
    "The top ten terms, sorted by reverse-inference posterior probability, from the BrainMap chi-squared decoding method.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d71ce",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Here we delete the recent variables for the sake of reducing memory usage\n",
    "del brainmap_decoder, brainmap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18afd04",
   "metadata": {},
   "source": [
    "### Neurosynth method\n",
    "\n",
    "The implementation of the MKDA Chi-squared meta-analysis method used by Neurosynth is quite similar to BrainMap’s method for decoding, if applied to annotations instead of modeled activation values.\n",
    "This method, implemented in {py:class}`nimare.decode.discrete.NeurosynthDecoder`, compares the distributions of studies with each label within the sample against those in a larger database, but, unlike the BrainMap method, does not take foci into account.\n",
    "For this reason, the Neurosynth method would likely be more appropriate for selection criteria not based on regions of interest (e.g., for characterizing meta-analytic groupings from a meta-analytic clustering analysis).\n",
    "However, the Neurosynth method requires user-provided information that BrainMap does not.\n",
    "Namely, in order to estimate probabilities for the consistency and specificity analyses with Bayes’ Theorem, the Neurosynth method requires a prior probability of a given label.\n",
    "Typically, a value of 0.5 is used (i.e., the estimated probability that an individual is undergoing a given mental process described by a label, barring any evidence from neuroimaging data, is predicted to be 50%).\n",
    "This is, admittedly, a poor prediction, which means that probabilities estimated based on this prior are not likely to be accurate, though they may still serve as useful estimates of effect size for the analysis.\n",
    "\n",
    "Like the BrainMap method, this method produces four outputs for each label.\n",
    "For the consistency analysis, this method produces both a p-value and a conditional probability of selection given the presence of the label and the prior probability of having the label.\n",
    "For the specificity analysis, the Neurosynth method produces both a p-value and a posterior probability of presence of the label given selection and the prior probability of having the label.\n",
    "A detailed algorithm description is presented in **Appendix II**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd1e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_decoder = decode.discrete.NeurosynthDecoder(\n",
    "    frequency_threshold=0.001,\n",
    "    u=0.05,\n",
    "    correction=\"fdr_bh\",\n",
    "    features=target_features,\n",
    ")\n",
    "neurosynth_decoder.fit(neurosynth_dset_first500)\n",
    "neurosynth_df = neurosynth_decoder.transform(amygdala_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311bfd3",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "neurosynth_df = neurosynth_df.reindex(\n",
    "    neurosynth_df[\"probReverse\"].abs().sort_values(ascending=False).index\n",
    ")\n",
    "neurosynth_df = neurosynth_df.iloc[:10]\n",
    "glue(\"table_neurosynth\", neurosynth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de9c1c",
   "metadata": {},
   "source": [
    "```{glue:figure} table_neurosynth\n",
    ":figwidth: 300px\n",
    ":name: \"tbl:table_neurosynth\"\n",
    ":align: center\n",
    "\n",
    "The top ten terms, sorted by reverse-inference posterior probability, from the Neurosynth chi-squared decoding method.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3066946",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Here we delete the recent variables for the sake of reducing memory usage\n",
    "del neurosynth_decoder, neurosynth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c055af4a",
   "metadata": {},
   "source": [
    "In both methods, the database acts as an estimate of the underlying distribution of labels in the real world, such that the probability of having a peak in an ROI given the presence of the label might be interpreted as the probability of a brain activating a specific brain region given that the individual is experiencing a given mental state.\n",
    "This is a very poor interpretation, given that any database of neuroimaging results will be skewed more toward the interests of the field than the distribution of mental states or processes experienced by humans, which is why decoding must be interpreted with extreme caution.\n",
    "It is important not to place too much emphasis on the results of functional decoding analyses, although they are very useful in that they can provide a quantitative estimate behind the kinds of interpretations generally included in discussion sections that are normally only backed by informal literature searches or prior knowledge.\n",
    "\n",
    "The meta-analytic functional decoding methods in NiMARE provide a very rudimentary approach for open-ended decoding (i.e., decoding across a very large range of mental states) that can be used with resources like NeuroVault.\n",
    "However, standard classification methods have also been applied to datasets from NeuroVault (e.g., {cite:t}`Varoquaux2018-lo`), although these methods do not fall under NiMARE's scope."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "source_map": [
   12,
   18,
   29,
   66,
   77,
   92,
   106,
   113,
   123,
   129,
   143,
   154,
   159,
   169,
   173,
   184,
   201,
   212,
   219,
   229,
   235,
   252,
   263,
   270,
   280,
   286
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}