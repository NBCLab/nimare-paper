
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Meta-Analytic Functional Decoding &#8212; NiMARE: Neuroimaging Meta-Analysis Research Environment</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="_static/nimare_favicon.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Future Directions" href="13_future_directions.html" />
    <link rel="prev" title="Automated Annotation" href="11_annotation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/nimare_overview.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NiMARE: Neuroimaging Meta-Analysis Research Environment</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="00_abstract.html">
   Abstract
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  About NiMARE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_overview.html">
   NiMARE Overview
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Meta-Analytic Databases and Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="03_download_data.html">
   Download the Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_resources.html">
   External Meta-Analytic Resources
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Meta-Analyses in NiMARE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="05_cbma.html">
   Coordinate-Based Meta-Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_ibma.html">
   Image-Based Meta-Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_correction.html">
   Multiple Comparisons Correction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Other Meta-Analytic Approaches
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="08_about_derivative_analyses.html">
   Derivative Analyses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_subtraction.html">
   Meta-Analytic Subtraction Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_macm.html">
   Meta-Analytic Coactivation Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_annotation.html">
   Automated Annotation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Meta-Analytic Functional Decoding
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Concluding Thoughts
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="13_future_directions.html">
   Future Directions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14_summary.html">
   Summary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15_acknowledgements.html">
   Acknowledgements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16_bibliography.html">
   References
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="appendices/brainmap_decoding.html">
   Appendix I: BrainMap Discrete Decoding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="appendices/neurosynth_decoding.html">
   Appendix II: Neurosynth Discrete Decoding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17_build_information.html">
   Build Information
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/12_decoding.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/12_decoding.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/NBCLab/nimare-paper"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/NBCLab/nimare-paper/issues/new?title=Issue%20on%20page%20%2F12_decoding.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://binder.conp.cloud/v2/gh/NBCLab/nimare-paper/master?urlpath=tree/content/12_decoding.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decoding-continuous-inputs">
   Decoding continuous inputs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decoding-discrete-inputs">
   Decoding discrete inputs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#brainmap-method">
     BrainMap method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#neurosynth-method">
     Neurosynth method
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="meta-analytic-functional-decoding">
<h1>Meta-Analytic Functional Decoding<a class="headerlink" href="#meta-analytic-functional-decoding" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First, import the necessary modules and functions</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">plotting</span>
<span class="kn">from</span> <span class="nn">repo2data.repo2data</span> <span class="kn">import</span> <span class="n">Repo2Data</span>

<span class="c1"># Install the data if running locally, or points to cached data if running on neurolibre</span>
<span class="n">DATA_REQ_FILE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;../binder/data_requirement.json&quot;</span><span class="p">)</span>
<span class="n">repo2data</span> <span class="o">=</span> <span class="n">Repo2Data</span><span class="p">(</span><span class="n">DATA_REQ_FILE</span><span class="p">)</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="n">repo2data</span><span class="o">.</span><span class="n">install</span><span class="p">()</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="c1"># Set an output directory for any files generated during the book building process</span>
<span class="n">out_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;../outputs/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/data/nbc/misc-projects/Salo_NiMARE/conda_env/lib/python3.7/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.
  &quot;Numpy arrays.&quot;, FutureWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---- repo2data starting ----
/home/data/nbc/misc-projects/Salo_NiMARE/conda_env/lib/python3.7/site-packages/repo2data
Config from file :
/home/data/nbc/misc-projects/Salo_NiMARE/binder/data_requirement.json
Destination:
./../data/nimare-paper

Info : ./../data/nimare-paper already downloaded
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nimare</span> <span class="kn">import</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">meta</span>

<span class="n">neurosynth_dset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s2">&quot;neurosynth_dataset.pkl.gz&quot;</span><span class="p">))</span>

<span class="n">kern</span> <span class="o">=</span> <span class="n">meta</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">MKDAKernel</span><span class="p">(</span><span class="n">memory_limit</span><span class="o">=</span><span class="s2">&quot;500mb&quot;</span><span class="p">)</span>
<span class="n">neurosynth_dset_first500</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s2">&quot;neurosynth_dataset_first500_with_mkda_ma.pkl.gz&quot;</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Collect features for decoding</span>
<span class="c1"># We use any features that appear in &gt;10% of studies and &lt;90%.</span>
<span class="n">id_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;study_id&quot;</span><span class="p">,</span> <span class="s2">&quot;contrast_id&quot;</span><span class="p">]</span>
<span class="n">frequency_threshold</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">cols</span> <span class="o">=</span> <span class="n">neurosynth_dset_first500</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">columns</span>
<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cols</span> <span class="k">if</span> <span class="n">c</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">id_cols</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">neurosynth_dset_first500</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">copy</span><span class="p">()[</span><span class="n">cols</span><span class="p">]</span>
<span class="n">n_studies</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">feature_counts</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span> <span class="o">&gt;=</span> <span class="n">frequency_threshold</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">target_features</span> <span class="o">=</span> <span class="n">feature_counts</span><span class="o">.</span><span class="n">between</span><span class="p">(</span><span class="n">n_studies</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">n_studies</span> <span class="o">*</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="n">target_features</span> <span class="o">=</span> <span class="n">target_features</span><span class="p">[</span><span class="n">target_features</span><span class="p">]</span>
<span class="n">target_features</span> <span class="o">=</span> <span class="n">target_features</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">target_features</span><span class="p">)</span><span class="si">}</span><span class="s2"> features selected.&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">continuous_map</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;map_to_decode.nii.gz&quot;</span><span class="p">)</span>
<span class="n">amygdala_roi</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;amygdala_roi.nii.gz&quot;</span><span class="p">)</span>
<span class="n">amygdala_ids</span> <span class="o">=</span> <span class="n">neurosynth_dset_first500</span><span class="o">.</span><span class="n">get_studies_by_mask</span><span class="p">(</span><span class="n">amygdala_roi</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>95 features selected.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:nimare.dataset:Mask affine does not match Dataset affine. Assuming same space.
</pre></div>
</div>
</div>
</div>
<p>Functional decoding performed with meta-analytic data, refers to methods which attempt to predict mental states from neuroimaging data using a large-scale meta-analytic database <span id="id1">[<a class="reference internal" href="16_bibliography.html#id80">Smith <em>et al.</em>, 2009</a>]</span>.
Such analyses may also be referred to as “informal reverse inference” <span id="id2">[<a class="reference internal" href="16_bibliography.html#id37">Poldrack, 2011</a>]</span>, “functional characterization analysis” <span id="id3">[<a class="reference internal" href="16_bibliography.html#id54">Bzdok <em>et al.</em>, 2013</a>, <a class="reference internal" href="16_bibliography.html#id41">Cieslik <em>et al.</em>, 2013</a>, <a class="reference internal" href="16_bibliography.html#id20">Rottschy <em>et al.</em>, 2013</a>]</span>, “open-ended decoding” <span id="id4">[<a class="reference internal" href="16_bibliography.html#id83">Rubin <em>et al.</em>, 2017</a>]</span>, or simply “functional decoding” <span id="id5">[<a class="reference internal" href="16_bibliography.html#id18">Amft <em>et al.</em>, 2015</a>, <a class="reference internal" href="16_bibliography.html#id72">Bzdok <em>et al.</em>, 2013</a>, <a class="reference internal" href="16_bibliography.html#id71">Nickl-Jockschat <em>et al.</em>, 2015</a>]</span>.
While the terminology is far from standardized, we will refer to this method as <strong>meta-analytic functional decoding</strong> in order to distinguish it from alternative methods like multivariate decoding and model-based decoding <span id="id6">[<a class="reference internal" href="16_bibliography.html#id37">Poldrack, 2011</a>]</span>.
Meta-analytic functional decoding is often used in conjunction with MACM, meta-analytic clustering, meta-analytic parcellation, and meta-ICA, in order to characterize resulting brain regions, clusters, or components.
Meta-analytic functional decoding models have also been extended for the purpose of <strong>meta-analytic functional encoding</strong>, wherein text is used to generate statistical images <span id="id7">[<a class="reference internal" href="16_bibliography.html#id83">Rubin <em>et al.</em>, 2017</a>, <a class="reference internal" href="16_bibliography.html#id3">Dockès <em>et al.</em>, 2018</a>, <a class="reference internal" href="16_bibliography.html#id24">Nunes, 2018</a>]</span>.</p>
<p>Four common approaches are correlation-based decoding, dot-product decoding, weight-sum decoding, and chi-square decoding.
We will first discuss continuous decoding methods (i.e., correlation and dot-product), followed by discrete decoding methods (weight-sum and chi-square).</p>
<div class="section" id="decoding-continuous-inputs">
<span id="content-decoding-continuous"></span><h2>Decoding continuous inputs<a class="headerlink" href="#decoding-continuous-inputs" title="Permalink to this headline">¶</a></h2>
<p>When decoding unthresholded statistical maps (such as <a class="reference internal" href="#figure-map-to-decode"><span class="std std-numref">Fig. 16</span></a>), the most common approaches are to simply correlate the input map with maps from the database, or to compute the dot product between the two maps.
In Neurosynth, meta-analyses are performed for each label (i.e., term or topic) in the database and then the input image is correlated with the resulting unthresholded statistical map from each meta-analysis.
Performing statistical inference on the resulting correlations is not straightforward, however, as voxels display strong spatial correlations, and the true degrees of freedom are consequently unknown (and likely far smaller than the nominal number of voxels).
In order to interpret the results of this decoding approach, users typically select some arbitrary number of top correlation coefficients ahead of time, and use the associated labels to describe the input map.
However, such results should be interpreted with great caution.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span><span class="n">continuous_map</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">annotate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;figure_map_to_decode&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/data/nbc/misc-projects/Salo_NiMARE/conda_env/lib/python3.7/site-packages/nilearn/_utils/niimg.py:62: UserWarning: Non-finite values detected. These values will be replaced with zeros.
  &quot;Non-finite values detected. &quot;
</pre></div>
</div>
<img alt="_images/12_decoding_5_2.png" src="_images/12_decoding_5_2.png" />
</div>
</div>
<div class="figure align-center" id="figure-map-to-decode">
<div class="cell_output docutils container">
<img alt="_images/12_decoding_5_1.png" src="_images/12_decoding_5_1.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 16 </span><span class="caption-text">The unthresholded statistical map that will be used for continuous decoding.</span><a class="headerlink" href="#figure-map-to-decode" title="Permalink to this image">¶</a></p>
</div>
<p>This approach can also be applied to an image-based database like NeuroVault, either by correlating input data with meta-analyzed statistical maps, or by deriving distributions of correlation coefficients by grouping statistical maps in the database according to label.
Using these distributions, it is possible to statistically compare labels in order to assess label significance.
NiMARE includes methods for both correlation-based decoding and correlation distribution-based decoding, although the correlation-based decoding is better established and should be preferred over the correlation distribution-based decoding.
As such, we will only show the <a class="reference external" href="https://nimare.readthedocs.io/en/0.0.10/generated/nimare.decode.continuous.CorrelationDecoder.html#nimare.decode.continuous.CorrelationDecoder" title="(in NiMARE v0.0.10+0.ge8814c2.dirty)"><code class="xref py py-class docutils literal notranslate"><span class="pre">CorrelationDecoder</span></code></a> here.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p><a class="reference external" href="https://nimare.readthedocs.io/en/0.0.10/generated/nimare.decode.continuous.CorrelationDecoder.html#nimare.decode.continuous.CorrelationDecoder" title="(in NiMARE v0.0.10+0.ge8814c2.dirty)"><code class="xref py py-class docutils literal notranslate"><span class="pre">CorrelationDecoder</span></code></a> currently runs <em>very</em> slowly.
We strongly recommend running it on a subset of labels within the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>.
It is also quite memory-intensive.</p>
<p>In this example, we have only run the decoder using features appearing in &gt;10% and &lt;90% of the first 500 studies in the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>.
Additionally, we have pre-generated the results and will simply show the code that <em>would</em> generate
those results, as the decoder requires too much memory for NeuroLibre’s servers.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nimare</span> <span class="kn">import</span> <span class="n">decode</span><span class="p">,</span> <span class="n">meta</span>

<span class="n">corr_decoder</span> <span class="o">=</span> <span class="n">decode</span><span class="o">.</span><span class="n">continuous</span><span class="o">.</span><span class="n">CorrelationDecoder</span><span class="p">(</span>
    <span class="n">frequency_threshold</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">meta_estimator</span><span class="o">=</span><span class="n">meta</span><span class="o">.</span><span class="n">MKDADensity</span><span class="p">(</span><span class="n">kernel_transformer</span><span class="o">=</span><span class="n">kern</span><span class="p">,</span> <span class="n">memory_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
    <span class="n">target_image</span><span class="o">=</span><span class="s2">&quot;z&quot;</span><span class="p">,</span>
    <span class="n">features</span><span class="o">=</span><span class="n">target_features</span><span class="p">,</span>
    <span class="n">memory_limit</span><span class="o">=</span><span class="s2">&quot;500mb&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">corr_decoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">neurosynth_dset_first500</span><span class="p">)</span>
<span class="n">corr_df</span> <span class="o">=</span> <span class="n">corr_decoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">continuous_map</span><span class="p">)</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">corr_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;correlation_decoder_results.tsv&quot;</span><span class="p">),</span>
    <span class="n">index_col</span><span class="o">=</span><span class="s2">&quot;feature&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_df</span> <span class="o">=</span> <span class="n">corr_df</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">corr_df</span><span class="p">[</span><span class="s2">&quot;r&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">corr_df</span> <span class="o">=</span> <span class="n">corr_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;table_corr&quot;</span><span class="p">,</span> <span class="n">corr_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>r</th>
    </tr>
    <tr>
      <th>feature</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>terms_abstract_tfidf__cingulate</th>
      <td>0.448665</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__anterior cingulate</th>
      <td>0.415396</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__anterior</th>
      <td>0.391049</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__auditory</th>
      <td>0.343746</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__conditions</th>
      <td>0.338773</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__cortices</th>
      <td>0.331308</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__information</th>
      <td>0.330473</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__role</th>
      <td>0.326022</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__level</th>
      <td>0.322515</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__healthy</th>
      <td>0.319750</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="figure align-center" id="tbl-table-corr">
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>r</th>
    </tr>
    <tr>
      <th>feature</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>terms_abstract_tfidf__cingulate</th>
      <td>0.448665</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__anterior cingulate</th>
      <td>0.415396</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__anterior</th>
      <td>0.391049</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__auditory</th>
      <td>0.343746</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__conditions</th>
      <td>0.338773</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__cortices</th>
      <td>0.331308</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__information</th>
      <td>0.330473</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__role</th>
      <td>0.326022</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__level</th>
      <td>0.322515</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__healthy</th>
      <td>0.319750</td>
    </tr>
  </tbody>
</table>
</div></div></div>
<p class="caption"><span class="caption-number">Fig. 17 </span><span class="caption-text">The top ten terms, sorted by absolute correlation coefficient, from the correlation decoding method.</span><a class="headerlink" href="#tbl-table-corr" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="decoding-discrete-inputs">
<span id="content-decoding-discrete"></span><h2>Decoding discrete inputs<a class="headerlink" href="#decoding-discrete-inputs" title="Permalink to this headline">¶</a></h2>
<p>Decoding regions of interest (ROIs) requires a different approach than decoding unthresholded statistical maps.
One simple approach, used by GCLDA and implemented in the function <a class="reference external" href="https://nimare.readthedocs.io/en/0.0.10/generated/nimare.decode.discrete.gclda_decode_roi.html#nimare.decode.discrete.gclda_decode_roi" title="(in NiMARE v0.0.10+0.ge8814c2.dirty)"><code class="xref py py-func docutils literal notranslate"><span class="pre">gclda_decode_roi()</span></code></a>, simply sums the <code class="docutils literal notranslate"><span class="pre">P(topic|voxel)</span></code> distribution across all voxels in the ROI in order to produce a value associated with each topic for the ROI.
These <strong>weight sum</strong> values are arbitrarily scaled and cannot be compared across ROIs.
We will not show this method because of its simplicity and the fact that it can only currently be applied to a GCLDA model.</p>
<p>Before we dig into the other decoding methods are are available, let’s take a look at the ROI we want to decode.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">amygdala_roi</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">annotate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;figure_roi_to_decode&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/12_decoding_11_1.png" src="_images/12_decoding_11_1.png" />
</div>
</div>
<div class="figure align-center" id="figure-roi-to-decode">
<div class="cell_output docutils container">
<img alt="_images/12_decoding_11_0.png" src="_images/12_decoding_11_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 18 </span><span class="caption-text">The amygdala region of interest mask that will be used for discrete decoding.</span><a class="headerlink" href="#figure-roi-to-decode" title="Permalink to this image">¶</a></p>
</div>
<p>One method which relies on correlations, much like the continuous correlation decoder, is the <strong>ROI association</strong> decoding method (<a class="reference external" href="https://nimare.readthedocs.io/en/0.0.10/generated/nimare.decode.discrete.ROIAssociationDecoder.html#nimare.decode.discrete.ROIAssociationDecoder" title="(in NiMARE v0.0.10+0.ge8814c2.dirty)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ROIAssociationDecoder</span></code></a>), originally implemented in the Neurosynth Python library.
In this method, each study with coordinates in the dataset is convolved with a kernel transformer to produce a modeled activation map.
The resulting modeled activation maps are then masked with a region of interest (i.e., the target of the decoding), and the values are averaged within the ROI.
These averaged modeled activation values are then correlated with the term weights for all labels in the dataset.
This decoding method produces a single correlation coefficient for each of the dataset’s labels.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Because the <code class="docutils literal notranslate"><span class="pre">ROIAssociationDecoder</span></code> generates modeled activation maps for all of the experiments in the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>, we will only fit this decoder to the first 500 studies.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nimare</span> <span class="kn">import</span> <span class="n">decode</span>

<span class="n">assoc_decoder</span> <span class="o">=</span> <span class="n">decode</span><span class="o">.</span><span class="n">discrete</span><span class="o">.</span><span class="n">ROIAssociationDecoder</span><span class="p">(</span>
    <span class="n">amygdala_roi</span><span class="p">,</span>
    <span class="n">kernel_transformer</span><span class="o">=</span><span class="n">kern</span><span class="p">,</span>
    <span class="n">u</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">correction</span><span class="o">=</span><span class="s2">&quot;fdr_bh&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">assoc_decoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">neurosynth_dset_first500</span><span class="p">)</span>
<span class="n">assoc_df</span> <span class="o">=</span> <span class="n">assoc_decoder</span><span class="o">.</span><span class="n">transform</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:nimare.base:Retaining 2941/(3228 features.
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">assoc_df</span> <span class="o">=</span> <span class="n">assoc_df</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">assoc_df</span><span class="p">[</span><span class="s2">&quot;r&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">assoc_df</span> <span class="o">=</span> <span class="n">assoc_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;table_assoc&quot;</span><span class="p">,</span> <span class="n">assoc_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>r</th>
    </tr>
    <tr>
      <th>feature</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>terms_abstract_tfidf__amygdala</th>
      <td>0.627186</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__fear</th>
      <td>0.334112</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__reinforcement</th>
      <td>0.329516</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__neutral faces</th>
      <td>0.320801</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__appraisal</th>
      <td>0.317214</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__conditioning</th>
      <td>0.286165</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__age sex</th>
      <td>0.273753</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__neutral</th>
      <td>0.272666</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__amygdala response</th>
      <td>0.267777</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__olfactory</th>
      <td>0.265687</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="figure align-center" id="tbl-table-assoc">
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>r</th>
    </tr>
    <tr>
      <th>feature</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>terms_abstract_tfidf__amygdala</th>
      <td>0.627186</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__fear</th>
      <td>0.334112</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__reinforcement</th>
      <td>0.329516</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__neutral faces</th>
      <td>0.320801</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__appraisal</th>
      <td>0.317214</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__conditioning</th>
      <td>0.286165</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__age sex</th>
      <td>0.273753</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__neutral</th>
      <td>0.272666</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__amygdala response</th>
      <td>0.267777</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__olfactory</th>
      <td>0.265687</td>
    </tr>
  </tbody>
</table>
</div></div></div>
<p class="caption"><span class="caption-number">Fig. 19 </span><span class="caption-text">The top ten terms, sorted by absolute correlation coefficient, from the ROI association decoding method.</span><a class="headerlink" href="#tbl-table-assoc" title="Permalink to this image">¶</a></p>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Here we delete the recent variables for the sake of reducing memory usage</span>
<span class="k">del</span> <span class="n">assoc_decoder</span><span class="p">,</span> <span class="n">assoc_df</span>
</pre></div>
</div>
</div>
</div>
<p>A more theoretically driven approach to ROI decoding is to use <strong>chi-square-based</strong> methods.
The two methods which use chi-squared tests are the BrainMap decoding method and an adaptation of Neurosynth’s meta-analysis method.</p>
<p>In both chi-square-based methods, studies are first selected from a coordinate-based database according to some criterion.
For example, if decoding a region of interest, users might select studies reporting at least one coordinate within 5 mm of the ROI.
Metadata (such as ontological labels) for this subset of studies are then compared to those of the remaining, unselected portion of the database in a confusion matrix.
For each label in the ontology, studies are divided into four groups: selected and label-positive (SS+L+), selected and label-negative (SS+L-), unselected and label-positive (SS-L+), and unselected and label-negative (SS-L-).
Each method then compares these groups in order to evaluate both consistency and specificity of the relationship between the selection criteria and each label, which are evaluated in terms of both statistical significance and effect size.</p>
<div class="section" id="brainmap-method">
<h3>BrainMap method<a class="headerlink" href="#brainmap-method" title="Permalink to this headline">¶</a></h3>
<p>The BrainMap discrete decoding method, implemented in <a class="reference external" href="https://nimare.readthedocs.io/en/0.0.10/generated/nimare.decode.discrete.BrainMapDecoder.html#nimare.decode.discrete.BrainMapDecoder" title="(in NiMARE v0.0.10+0.ge8814c2.dirty)"><code class="xref py py-class docutils literal notranslate"><span class="pre">BrainMapDecoder</span></code></a>, compares the distributions of studies with each label within the sample against those in a larger database while accounting for the number of foci from each study.
Broadly speaking, this method assumes that the selection criterion is associated with one peak per study, which means that it is likely only appropriate for selection criteria based around foci, such as regions of interest.
One common analysis, meta-analytic clustering, involves dividing studies within a database into meta-analytic groupings based on the spatial similarity of their modeled activation maps (i.e., study-wise pseudo-statistical maps produced by convolving coordinates with a kernel).
The resulting sets of studies are often functionally decoded in order to build a functional profile associated with each meta-analytic grouping.
While these groupings are defined as subsets of the database, they are not selected based on the location of an individual peak, and so weighting based on the number of foci would be inappropriate.</p>
<p>This decoding method produces four outputs for each label.
First, the distribution of studies in the sample with the label are compared to the distributions of other labels within the sample.
This consistency analysis produces both a measure of statistical significance (i.e., a p-value) and a measure of effect size (i.e., the likelihood of being selected given the presence of the label).
Next, the studies in the sample are compared to the studies in the rest of the database.
This specificity analysis produces a p-value and an effect size measure of the posterior probability of having the label given selection into the sample.
A detailed algorithm description is presented in <a class="reference internal" href="appendices/brainmap_decoding.html"><span class="doc std std-doc">Appendix I: BrainMap Discrete Decoding</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">brainmap_decoder</span> <span class="o">=</span> <span class="n">decode</span><span class="o">.</span><span class="n">discrete</span><span class="o">.</span><span class="n">BrainMapDecoder</span><span class="p">(</span>
    <span class="n">frequency_threshold</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">u</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">correction</span><span class="o">=</span><span class="s2">&quot;fdr_bh&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">brainmap_decoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">neurosynth_dset</span><span class="p">)</span>
<span class="n">brainmap_df</span> <span class="o">=</span> <span class="n">brainmap_decoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">amygdala_ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">brainmap_df</span> <span class="o">=</span> <span class="n">brainmap_df</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span>
    <span class="n">brainmap_df</span><span class="p">[</span><span class="s2">&quot;probReverse&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span>
<span class="p">)</span>
<span class="n">brainmap_df</span> <span class="o">=</span> <span class="n">brainmap_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;table_brainmap&quot;</span><span class="p">,</span> <span class="n">brainmap_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pForward</th>
      <th>zForward</th>
      <th>likelihoodForward</th>
      <th>pReverse</th>
      <th>zReverse</th>
      <th>probReverse</th>
    </tr>
    <tr>
      <th>Term</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>terms_abstract_tfidf__magnetic</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.627342</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.011441</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__magnetic resonance</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.569942</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.010827</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__resonance</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.560855</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.010815</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__amygdala</th>
      <td>6.176744e-07</td>
      <td>4.985607</td>
      <td>6.407830</td>
      <td>2.152100e-18</td>
      <td>8.749022</td>
      <td>0.010609</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__functional magnetic</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.664782</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.010540</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__using</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.205627</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.007210</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__response</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.902148</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.007039</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__stimuli</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>2.087218</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.006286</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__human</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>2.128483</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.005356</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__neutral</th>
      <td>5.556739e-03</td>
      <td>2.772852</td>
      <td>5.502956</td>
      <td>2.753866e-06</td>
      <td>4.688372</td>
      <td>0.005320</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="figure align-center" id="tbl-table-brainmap">
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pForward</th>
      <th>zForward</th>
      <th>likelihoodForward</th>
      <th>pReverse</th>
      <th>zReverse</th>
      <th>probReverse</th>
    </tr>
    <tr>
      <th>Term</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>terms_abstract_tfidf__magnetic</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.627342</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.011441</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__magnetic resonance</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.569942</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.010827</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__resonance</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.560855</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.010815</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__amygdala</th>
      <td>6.176744e-07</td>
      <td>4.985607</td>
      <td>6.407830</td>
      <td>2.152100e-18</td>
      <td>8.749022</td>
      <td>0.010609</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__functional magnetic</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.664782</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.010540</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__using</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.205627</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.007210</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__response</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>1.902148</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.007039</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__stimuli</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>2.087218</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.006286</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__human</th>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>2.128483</td>
      <td>1.000000e+00</td>
      <td>0.000000</td>
      <td>0.005356</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__neutral</th>
      <td>5.556739e-03</td>
      <td>2.772852</td>
      <td>5.502956</td>
      <td>2.753866e-06</td>
      <td>4.688372</td>
      <td>0.005320</td>
    </tr>
  </tbody>
</table>
</div></div></div>
<p class="caption"><span class="caption-number">Fig. 20 </span><span class="caption-text">The top ten terms, sorted by reverse-inference posterior probability, from the BrainMap chi-squared decoding method.</span><a class="headerlink" href="#tbl-table-brainmap" title="Permalink to this image">¶</a></p>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Here we delete the recent variables for the sake of reducing memory usage</span>
<span class="k">del</span> <span class="n">brainmap_decoder</span><span class="p">,</span> <span class="n">brainmap_df</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="neurosynth-method">
<h3>Neurosynth method<a class="headerlink" href="#neurosynth-method" title="Permalink to this headline">¶</a></h3>
<p>The implementation of the MKDA Chi-squared meta-analysis method used by Neurosynth is quite similar to BrainMap’s method for decoding, if applied to annotations instead of modeled activation values.
This method, implemented in <a class="reference external" href="https://nimare.readthedocs.io/en/0.0.10/generated/nimare.decode.discrete.NeurosynthDecoder.html#nimare.decode.discrete.NeurosynthDecoder" title="(in NiMARE v0.0.10+0.ge8814c2.dirty)"><code class="xref py py-class docutils literal notranslate"><span class="pre">NeurosynthDecoder</span></code></a>, compares the distributions of studies with each label within the sample against those in a larger database, but, unlike the BrainMap method, does not take foci into account.
For this reason, the Neurosynth method would likely be more appropriate for selection criteria not based on regions of interest (e.g., for characterizing meta-analytic groupings from a meta-analytic clustering analysis).
However, the Neurosynth method requires user-provided information that BrainMap does not.
Namely, in order to estimate probabilities for the consistency and specificity analyses with Bayes’ Theorem, the Neurosynth method requires a prior probability of a given label.
Typically, a value of 0.5 is used (i.e., the estimated probability that an individual is undergoing a given mental process described by a label, barring any evidence from neuroimaging data, is predicted to be 50%).
This is, admittedly, a poor prediction, which means that probabilities estimated based on this prior are not likely to be accurate, though they may still serve as useful estimates of effect size for the analysis.</p>
<p>Like the BrainMap method, this method produces four outputs for each label.
For the consistency analysis, this method produces both a p-value and a conditional probability of selection given the presence of the label and the prior probability of having the label.
For the specificity analysis, the Neurosynth method produces both a p-value and a posterior probability of presence of the label given selection and the prior probability of having the label.
A detailed algorithm description is presented in <a class="reference internal" href="appendices/neurosynth_decoding.html"><span class="doc std std-doc">Appendix II: Neurosynth Discrete Decoding</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">neurosynth_decoder</span> <span class="o">=</span> <span class="n">decode</span><span class="o">.</span><span class="n">discrete</span><span class="o">.</span><span class="n">NeurosynthDecoder</span><span class="p">(</span>
    <span class="n">frequency_threshold</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">u</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">correction</span><span class="o">=</span><span class="s2">&quot;fdr_bh&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">neurosynth_decoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">neurosynth_dset</span><span class="p">)</span>
<span class="n">neurosynth_df</span> <span class="o">=</span> <span class="n">neurosynth_decoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">amygdala_ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">neurosynth_df</span> <span class="o">=</span> <span class="n">neurosynth_df</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span>
    <span class="n">neurosynth_df</span><span class="p">[</span><span class="s2">&quot;probReverse&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span>
<span class="p">)</span>
<span class="n">neurosynth_df</span> <span class="o">=</span> <span class="n">neurosynth_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;table_neurosynth&quot;</span><span class="p">,</span> <span class="n">neurosynth_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pForward</th>
      <th>zForward</th>
      <th>probForward</th>
      <th>pReverse</th>
      <th>zReverse</th>
      <th>probReverse</th>
    </tr>
    <tr>
      <th>Term</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>terms_abstract_tfidf__neutral faces</th>
      <td>6.163179e-12</td>
      <td>6.875826</td>
      <td>0.024702</td>
      <td>4.685748e-31</td>
      <td>11.588999</td>
      <td>0.971583</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__conditioning</th>
      <td>1.026669e-16</td>
      <td>8.301660</td>
      <td>0.022543</td>
      <td>1.221816e-32</td>
      <td>11.897339</td>
      <td>0.970346</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__olfactory</th>
      <td>1.482800e-02</td>
      <td>2.436553</td>
      <td>0.021075</td>
      <td>2.058612e-12</td>
      <td>7.030455</td>
      <td>0.961833</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__conditioned</th>
      <td>7.813282e-05</td>
      <td>3.950056</td>
      <td>0.017439</td>
      <td>2.697558e-13</td>
      <td>7.308692</td>
      <td>0.955737</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__reinforcement</th>
      <td>7.813282e-05</td>
      <td>3.950056</td>
      <td>0.016397</td>
      <td>2.058612e-12</td>
      <td>7.030455</td>
      <td>0.952900</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__unpleasant</th>
      <td>7.813282e-05</td>
      <td>3.950056</td>
      <td>0.015924</td>
      <td>4.616361e-12</td>
      <td>6.916899</td>
      <td>0.951487</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__amygdala</th>
      <td>1.953150e-123</td>
      <td>23.628732</td>
      <td>0.006013</td>
      <td>2.152100e-18</td>
      <td>8.749022</td>
      <td>0.947992</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__amygdala response</th>
      <td>1.482800e-02</td>
      <td>2.436553</td>
      <td>0.014081</td>
      <td>1.526484e-07</td>
      <td>5.249336</td>
      <td>0.942719</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__differentiated</th>
      <td>1.482800e-02</td>
      <td>2.436553</td>
      <td>0.014081</td>
      <td>1.526484e-07</td>
      <td>5.249336</td>
      <td>0.942719</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__pleasant</th>
      <td>1.482800e-02</td>
      <td>2.436553</td>
      <td>0.013307</td>
      <td>5.206710e-07</td>
      <td>5.018535</td>
      <td>0.939358</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="figure align-center" id="tbl-table-neurosynth">
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pForward</th>
      <th>zForward</th>
      <th>probForward</th>
      <th>pReverse</th>
      <th>zReverse</th>
      <th>probReverse</th>
    </tr>
    <tr>
      <th>Term</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>terms_abstract_tfidf__neutral faces</th>
      <td>6.163179e-12</td>
      <td>6.875826</td>
      <td>0.024702</td>
      <td>4.685748e-31</td>
      <td>11.588999</td>
      <td>0.971583</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__conditioning</th>
      <td>1.026669e-16</td>
      <td>8.301660</td>
      <td>0.022543</td>
      <td>1.221816e-32</td>
      <td>11.897339</td>
      <td>0.970346</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__olfactory</th>
      <td>1.482800e-02</td>
      <td>2.436553</td>
      <td>0.021075</td>
      <td>2.058612e-12</td>
      <td>7.030455</td>
      <td>0.961833</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__conditioned</th>
      <td>7.813282e-05</td>
      <td>3.950056</td>
      <td>0.017439</td>
      <td>2.697558e-13</td>
      <td>7.308692</td>
      <td>0.955737</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__reinforcement</th>
      <td>7.813282e-05</td>
      <td>3.950056</td>
      <td>0.016397</td>
      <td>2.058612e-12</td>
      <td>7.030455</td>
      <td>0.952900</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__unpleasant</th>
      <td>7.813282e-05</td>
      <td>3.950056</td>
      <td>0.015924</td>
      <td>4.616361e-12</td>
      <td>6.916899</td>
      <td>0.951487</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__amygdala</th>
      <td>1.953150e-123</td>
      <td>23.628732</td>
      <td>0.006013</td>
      <td>2.152100e-18</td>
      <td>8.749022</td>
      <td>0.947992</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__amygdala response</th>
      <td>1.482800e-02</td>
      <td>2.436553</td>
      <td>0.014081</td>
      <td>1.526484e-07</td>
      <td>5.249336</td>
      <td>0.942719</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__differentiated</th>
      <td>1.482800e-02</td>
      <td>2.436553</td>
      <td>0.014081</td>
      <td>1.526484e-07</td>
      <td>5.249336</td>
      <td>0.942719</td>
    </tr>
    <tr>
      <th>terms_abstract_tfidf__pleasant</th>
      <td>1.482800e-02</td>
      <td>2.436553</td>
      <td>0.013307</td>
      <td>5.206710e-07</td>
      <td>5.018535</td>
      <td>0.939358</td>
    </tr>
  </tbody>
</table>
</div></div></div>
<p class="caption"><span class="caption-number">Fig. 21 </span><span class="caption-text">The top ten terms, sorted by reverse-inference posterior probability, from the Neurosynth chi-squared decoding method.</span><a class="headerlink" href="#tbl-table-neurosynth" title="Permalink to this image">¶</a></p>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Here we delete the recent variables for the sake of reducing memory usage</span>
<span class="k">del</span> <span class="n">neurosynth_decoder</span><span class="p">,</span> <span class="n">neurosynth_df</span>
</pre></div>
</div>
</div>
</div>
<p>In both methods, the database acts as an estimate of the underlying distribution of labels in the real world, such that the probability of having a peak in an ROI given the presence of the label might be interpreted as the probability of a brain activating a specific brain region given that the individual is experiencing a given mental state.
This is a very poor interpretation, given that any database of neuroimaging results will be skewed more toward the interests of the field than the distribution of mental states or processes experienced by humans, which is why decoding must be interpreted with extreme caution.
It is important not to place too much emphasis on the results of functional decoding analyses, although they are very useful in that they can provide a quantitative estimate behind the kinds of interpretations generally included in discussion sections that are normally only backed by informal literature searches or prior knowledge.</p>
<p>The meta-analytic functional decoding methods in NiMARE provide a very rudimentary approach for open-ended decoding (i.e., decoding across a very large range of mental states) that can be used with resources like NeuroVault.
However, standard classification methods have also been applied to datasets from NeuroVault (e.g., <span id="id8">Varoquaux <em>et al.</em> [<a class="reference internal" href="16_bibliography.html#id55">2018</a>]</span>), although these methods do not fall under NiMARE’s scope.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="11_annotation.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Automated Annotation</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="13_future_directions.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Future Directions</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Taylor Salo, Tal Yarkoni, Thomas E. Nichols, Jean-Baptiste Poline, Murat Bilgel, Katherine L. Bottenhorn, Dorota Jarecka, James D. Kent, Adam Kimbler, Dylan M. Nielson, Kendra M. Oudyk, Julio A. Peraza, Alexandre Pérez, Puck C. Reeders, Julio A. Yanes, and Angela R. Laird<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>