{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279a0270",
   "metadata": {},
   "source": [
    "# Image-Based Meta-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c264d1",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/nbc/misc-projects/Salo_NiMARE/conda_env/lib/python3.7/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- repo2data starting ----\n",
      "/home/data/nbc/misc-projects/Salo_NiMARE/conda_env/lib/python3.7/site-packages/repo2data\n",
      "Config from file :\n",
      "/home/data/nbc/misc-projects/Salo_NiMARE/binder/data_requirement.json\n",
      "Destination:\n",
      "./../data/nimare-paper\n",
      "\n",
      "Info : ./../data/nimare-paper already downloaded\n"
     ]
    }
   ],
   "source": [
    "# First, import the necessary modules and functions\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from myst_nb import glue\n",
    "from nilearn import plotting\n",
    "from repo2data.repo2data import Repo2Data\n",
    "\n",
    "# Install the data if running locally, or points to cached data if running on neurolibre\n",
    "DATA_REQ_FILE = os.path.abspath(\"../binder/data_requirement.json\")\n",
    "repo2data = Repo2Data(DATA_REQ_FILE)\n",
    "data_path = repo2data.install()\n",
    "data_path = os.path.join(data_path[0], \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e436aa6",
   "metadata": {},
   "source": [
    "Image-based meta-analysis (IBMA) methods perform a meta-analysis directly on brain images (either whole-brain or partial) rather than on extracted peaks.\n",
    "On paper, IBMA is superior to CBMA in virtually all respects, as the availability of analysis-level parameter and variance estimates at all analyzed voxels allows researchers to use the full complement of standard meta-analysis techniques, instead of having to resort to kernel-based or other methods that require additional spatial assumptions.\n",
    "In principle, given a set of maps that contains no missing values (i.e., where there are _k_ valid pairs of parameter and variance estimates at each voxel), one can simply conduct a voxel-wise version of any standard meta-analysis or meta-regression method commonly used in other biomedical or social science fields.\n",
    "\n",
    "In practice, the utility of IBMA methods has historically been quite limited, as unthresholded statistical maps have been unavailable for the vast majority of neuroimaging studies.\n",
    "However, the introduction and rapid adoption of NeuroVault {cite:p}`Gorgolewski2015-sd`, a database for unthresholded statistical images, has made image-based meta-analysis increasingly viable.\n",
    "Although coverage of the literature remains limited, and IBMAs of maps drawn from the NeuroVault database are likely to omit at least some (and in some cases most) relevant studies due to limited metadata,  we believe the time is ripe for researchers to start including both CBMAs and IBMAs in published meta-analyses, with the aspirational goal of eventually transitioning exclusively to the latter.\n",
    "To this end, NiMARE supports a range of different IBMA methods, including a number of estimators of the gold standard mixed-effects meta-regression model, as well as several alternative estimators suitable for use when some of the traditional inputs are unavailable.\n",
    "\n",
    "```{note}\n",
    "NiMARE's IBMA `Estimator`s are light wrappers around classes from [PyMARE](https://pymare.readthedocs.io), a library for standard (i.e., non-neuroimaging) meta-analyses developed by the same team as NiMARE.\n",
    "```\n",
    "\n",
    "In the optimal situation, meta-analysts have access to both contrast (i.e., parameter estimate) maps and their associated standard error maps for a number of studies.\n",
    "With these data, researchers can fit the traditional random-effects meta-regression model using one of several methods that vary in the way they estimate the between-study variance ($\\tau^{2}$).\n",
    "Currently supported estimators include the **DerSimonian-Laird** method {cite:p}`DerSimonian1986-hu`, the **Hedges** method {cite:p}`Hedges1985-ka`, and **maximum-likelihood** (ML) and **restricted maximum-likelihood** (REML) approaches.\n",
    "NiMARE can also perform fixed-effects meta-regression via weighted least-squares, though there are few IBMA scenarios where a fixed-effects analysis would be indicated.\n",
    "It is worth noting that the non-likelihood-based estimators (i.e., DerSimonian-Laird and Hedges) have a closed-form solution, and are implemented in an extremely efficient way in NiMARE (i.e., computation is performed on all voxels in parallel).\n",
    "However, these estimators also produce more biased estimates under typical conditions (e.g., when sample sizes are very small), implying a tradeoff from the user's perspective.\n",
    "\n",
    "Alternatively, when users only have access to contrast maps and associated sample sizes, they can use the supported **Sample Size-Based Likelihood** estimator, which assumes that within-study variance is constant across studies, and uses maximum-likelihood or restricted maximum-likelihood to estimate between-study variance, as described in {cite:t}`Sangnawakij2019-mq`.\n",
    "When users have access only to contrast maps, they can use the **Permuted OLS** estimator, which uses ordinary least squares and employs a max-type permutation scheme for family-wise error correction {cite:p}`Freedman1983-ld,Anderson2001-uc` that has been validated on neuroimaging data {cite:p}`Winkler2014-wh` and relies on the nilearn library.\n",
    "\n",
    "Finally, when users only have access to z-score maps, they can use either the **Fisher's** {cite:p}`Fisher1925-zh` or the **Stouffer's** {cite:p}`Riley1949-uz` estimators.\n",
    "When sample size information is available, users may incorporate that information into the Stouffer's method, via the method described in {cite:t}`Zaykin2011-fs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4d3a7",
   "metadata": {},
   "source": [
    "Given the paucity of image-based meta-analytic datasets, we have included the tools to build a Dataset from a NeuroVault collection of 21 pain studies, originally described in {cite:t}`Maumet2016-rr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6aa2032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.extract.utils:Dataset found in ./../data/nimare-paper/data/nidm_21pain\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/data/nbc/misc-projects/Salo_NiMARE/conda_env/lib/python3.7/site-packages/nimare/resources/nidm_pain_dset.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24849/2439021973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_nidm_pain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdset_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resource_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nidm_pain_dset.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimg_dset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Point the Dataset toward the images we've downloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/data/nbc/misc-projects/Salo_NiMARE/conda_env/lib/python3.7/site-packages/nimare/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, target, mask)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mni152_2mm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/data/nbc/misc-projects/Salo_NiMARE/conda_env/lib/python3.7/site-packages/nimare/resources/nidm_pain_dset.json'"
     ]
    }
   ],
   "source": [
    "from nimare import dataset, extract, utils\n",
    "\n",
    "dset_dir = extract.download_nidm_pain(data_dir=data_path, overwrite=False)\n",
    "dset_file = os.path.join(utils.get_resource_path(), \"nidm_pain_dset.json\")\n",
    "img_dset = dataset.Dataset(dset_file)\n",
    "\n",
    "# Point the Dataset toward the images we've downloaded\n",
    "img_dset.update_path(dset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81881c82",
   "metadata": {},
   "source": [
    "## Transforming images\n",
    "\n",
    "Researchers may share their statistical maps in many forms, some of which are direct transformations of one another.\n",
    "For example, researchers may share test statistic maps with z-statistics or t-statistics, and, as long as we know the degrees of freedom associated with the t-test, we can convert between the two easily. To that end, NiMARE includes a class, {py:class}`nimare.transforms.ImageTransformer`, which will calculate target image types from available ones, as long as the available images are compatible with said transformation.\n",
    "\n",
    "Here, we use `ImageTransformer` to calculate z-statistic and variance maps for all studies with compatible images.\n",
    "This allows us to apply more image-based meta-analysis algorithms to the `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimare import transforms\n",
    "\n",
    "img_transformer = transforms.ImageTransformer(target=[\"z\", \"varcope\"], overwrite=False)\n",
    "img_dset = img_transformer.transform(img_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a530d",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Here we delete the recent variables for the sake of reducing memory usage\n",
    "del img_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37939d30",
   "metadata": {},
   "source": [
    "Now that we have filled in as many gaps in the `Dataset` as possible, we can start running meta-analyses.\n",
    "We will start with a DerSimonian-Laird meta-analysis ({py:class}`nimare.meta.ibma.DerSimonianLaird`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65578058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimare import meta\n",
    "\n",
    "dsl_meta = meta.ibma.DerSimonianLaird()\n",
    "dsl_results = dsl_meta.fit(img_dset)\n",
    "\n",
    "# Retain the z-statistic map for later use\n",
    "dsl_img = dsl_results.get_map(\"z\", return_type=\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de8dff",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Here we delete the recent variables for the sake of reducing memory usage\n",
    "del dsl_meta, dsl_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df42799",
   "metadata": {},
   "source": [
    "Now we will apply other available IBMA `Estimator`s to the same `Dataset`, and save their results to files for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f24a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stouffer's\n",
    "stouffers_meta = meta.ibma.Stouffers(use_sample_size=False)\n",
    "stouffers_results = stouffers_meta.fit(img_dset)\n",
    "stouffers_img = stouffers_results.get_map(\"z\", return_type=\"image\")\n",
    "del stouffers_meta, stouffers_results\n",
    "\n",
    "# Stouffer's with weighting based on sample size\n",
    "wstouffers_meta = meta.ibma.Stouffers(use_sample_size=True)\n",
    "wstouffers_results = wstouffers_meta.fit(img_dset)\n",
    "wstouffers_img = wstouffers_results.get_map(\"z\", return_type=\"image\")\n",
    "del wstouffers_meta, wstouffers_results\n",
    "\n",
    "# Fisher's\n",
    "fishers_meta = meta.ibma.Fishers()\n",
    "fishers_results = fishers_meta.fit(img_dset)\n",
    "fishers_img = fishers_results.get_map(\"z\", return_type=\"image\")\n",
    "del fishers_meta, fishers_results\n",
    "\n",
    "# Permuted Ordinary Least Squares\n",
    "ols_meta = meta.ibma.PermutedOLS()\n",
    "ols_results = ols_meta.fit(img_dset)\n",
    "ols_img = ols_results.get_map(\"z\", return_type=\"image\")\n",
    "del ols_meta, ols_results\n",
    "\n",
    "# Weighted Least Squares\n",
    "wls_meta = meta.ibma.WeightedLeastSquares()\n",
    "wls_results = wls_meta.fit(img_dset)\n",
    "wls_img = wls_results.get_map(\"z\", return_type=\"image\")\n",
    "del wls_meta, wls_results\n",
    "\n",
    "# Hedges'\n",
    "hedges_meta = meta.ibma.Hedges()\n",
    "hedges_results = hedges_meta.fit(img_dset)\n",
    "hedges_img = hedges_results.get_map(\"z\", return_type=\"image\")\n",
    "del hedges_meta, hedges_results\n",
    "\n",
    "# Use atlas for likelihood-based estimators\n",
    "from nilearn import datasets, image, input_data\n",
    "\n",
    "atlas = datasets.fetch_atlas_harvard_oxford(\"cort-maxprob-thr25-2mm\")\n",
    "\n",
    "# nilearn's NiftiLabelsMasker cannot handle NaNs at the moment,\n",
    "# and some of the NIDM-Results packs' beta images have NaNs at the edge of the brain.\n",
    "# So, we will create a reduced version of the atlas for this analysis.\n",
    "nan_mask = image.math_img(\"~np.any(np.isnan(img), axis=3)\", img=img_dset.images[\"beta\"].tolist())\n",
    "nanmasked_atlas = image.math_img(\"mask * atlas\", mask=nan_mask, atlas=atlas[\"maps\"])\n",
    "masker = input_data.NiftiLabelsMasker(nanmasked_atlas)\n",
    "del atlas, nan_mask, nanmasked_atlas\n",
    "\n",
    "# Variance-Based Likelihood\n",
    "vbl_meta = meta.ibma.VarianceBasedLikelihood(method=\"reml\", mask=masker)\n",
    "vbl_results = vbl_meta.fit(img_dset)\n",
    "vbl_img = vbl_results.get_map(\"z\", return_type=\"image\")\n",
    "del vbl_meta, vbl_results\n",
    "\n",
    "# Sample Size-Based Likelihood\n",
    "ssbl_meta = meta.ibma.SampleSizeBasedLikelihood(method=\"reml\", mask=masker)\n",
    "ssbl_results = ssbl_meta.fit(img_dset)\n",
    "ssbl_img = ssbl_results.get_map(\"z\", return_type=\"image\")\n",
    "del ssbl_meta, ssbl_results, masker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4835d7d",
   "metadata": {},
   "source": [
    "## Comparing algorithms\n",
    "\n",
    "Here we load the z-statistic map from each of the IBMA Estimators we've used throughout this chapter and plot them all side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67fadea",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "meta_results = {\n",
    "    \"DerSimonian-Laird\": dsl_img,\n",
    "    \"Stouffer's\": stouffers_img,\n",
    "    \"Weighted Stouffer's\": wstouffers_img,\n",
    "    \"Fisher's\": fishers_img,\n",
    "    \"Ordinary Least Squares\": ols_img,\n",
    "    \"Weighted Least Squares\": wls_img,\n",
    "    \"Hedges'\": hedges_img,\n",
    "    \"Variance-Based Likelihood\": vbl_img,\n",
    "    \"Sample Size-Based Likelihood\": ssbl_img,\n",
    "}\n",
    "order = [\n",
    "    [\"Fisher's\", \"Stouffer's\", \"Weighted Stouffer's\"],\n",
    "    [\"DerSimonian-Laird\", \"Hedges'\", \"Weighted Least Squares\"],\n",
    "    [\"Ordinary Least Squares\", \"Variance-Based Likelihood\", \"Sample Size-Based Likelihood\"],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(18, 6), nrows=3, ncols=3)\n",
    "\n",
    "for i_row, row_names in enumerate(order):\n",
    "    for j_col, name in enumerate(row_names):\n",
    "        file_ = meta_results[name]\n",
    "        display = plotting.plot_stat_map(\n",
    "            file_,\n",
    "            annotate=False,\n",
    "            axes=axes[i_row, j_col],\n",
    "            cmap=\"RdBu_r\",\n",
    "            cut_coords=[5, -15, 10],\n",
    "            draw_cross=False,\n",
    "            figure=fig,\n",
    "        )\n",
    "        axes[i_row, j_col].set_title(name)\n",
    "\n",
    "        colorbar = display._cbar\n",
    "        colorbar_ticks = colorbar.get_ticks()\n",
    "        if colorbar_ticks[0] < 0:\n",
    "            new_ticks = [colorbar_ticks[0], 0, colorbar_ticks[-1]]\n",
    "        else:\n",
    "            new_ticks = [colorbar_ticks[0], colorbar_ticks[-1]]\n",
    "        colorbar.set_ticks(new_ticks, update_ticks=True)\n",
    "\n",
    "glue(\"figure_uncorr_ibma\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a8584",
   "metadata": {},
   "source": [
    "```{glue:figure} figure_uncorr_ibma\n",
    ":name: figure_uncorr_ibma\n",
    ":align: center\n",
    "\n",
    "An array of plots of the statistical maps produced by the image-based meta-analysis methods.\n",
    "The likelihood-based meta-analyses are run on atlases instead of voxelwise.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "source_map": [
   12,
   18,
   35,
   63,
   67,
   76,
   86,
   93,
   97,
   102,
   112,
   118,
   122,
   185,
   191,
   235
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}