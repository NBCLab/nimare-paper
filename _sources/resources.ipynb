{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d0ed93",
   "metadata": {},
   "source": [
    "# External Meta-Analytic Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ac7c35",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# First, import the necessary modules and functions\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import nimare\n",
    "\n",
    "# Define where data files will be located\n",
    "DATA_DIR = os.path.abspath(\"../data\")\n",
    "FIG_DIR = os.path.abspath(\"../images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114ae31",
   "metadata": {},
   "source": [
    "Large-scale meta-analytic databases have made systematic meta-analyses of the neuroimaging literature possible.\n",
    "These databases combine results from neuroimaging studies, whether represented as coordinates of peak activations or unthresholded statistical images, with important study metadata, such as information about the samples acquired, stimuli used, analyses performed, and mental constructs putatively manipulated.\n",
    "The two most popular coordinate-based meta-analytic databases are [BrainMap](http://www.brainmap.org) and [Neurosynth](http://neurosynth.org), while the most popular image-based database is [NeuroVault](https://neurovault.org).\n",
    "\n",
    "The studies archived in these databases may be either manually or automatically annotated—often with reference to a formal ontology or controlled vocabulary.\n",
    "Ontologies for cognitive neuroscience define what mental states or processes are postulated to be manipulated or measured in experiments, and may also include details of said experiments (e.g.,the cognitive tasks employed), relationships between concepts (e.g., verbal working memory is a kind of working memory), and various other metadata that can be standardized and represented in a machine-readable form {cite:p}`Poldrack2016-ym,Poldrack2010-jz,Turner2012-ai`.\n",
    "Some of these ontologies are very well-defined, such as expert-generated taxonomies designed specifically to describe only certain aspects of experiments and the relationships between elements within the taxonomy, while others are more loosely defined, in some cases simply building a vocabulary based on which terms are commonly used in cognitive neuroscience articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94beb549",
   "metadata": {},
   "source": [
    "(content:resources:brainmap)=\n",
    "## BrainMap\n",
    "\n",
    "**BrainMap** {cite:p}`Fox2005-rt,Fox2002-nv,Laird2005-al` relies on expert annotators to label individual comparisons within studies according to its internally developed ontology, the BrainMap Taxonomy {cite:p}`Fox2005-rt`.\n",
    "While this approach is likely to be less noisy than an automated annotation method using article text or imaging results to predict content, it is also subject to a number of limitations.\n",
    "First, there are simply not enough annotators to keep up with the ever-expanding literature.\n",
    "Second, any development of the underlying ontology has the potential to leave the database outdated.\n",
    "For example, if a new label is added to the BrainMap Taxonomy, then each study in the full BrainMap database needs to be evaluated for that label before that label can be properly integrated into the database.\n",
    "Finally, a manually annotated database like BrainMap will be biased by which subdomains within the literature are annotated.\n",
    "While outside contributors can add and annotate studies to the database, the main source of annotations has been researchers associated with the BrainMap project.\n",
    "\n",
    "While BrainMap is a semi-closed resource (i.e., a collaboration agreement is required to access the full database), registered users may search the database using the Sleuth search tool, in order to collect samples for meta-analyses.\n",
    "Sleuth can export these study collections as text files with coordinates.\n",
    "NiMARE provides a function to import data from Sleuth text files into the NiMARE Dataset format.\n",
    "\n",
    "The function {py:func}`nimare.io.convert_sleuth_to_dataset` can be used to convert text files exported from Sleuth into NiMARE `Dataset`s.\n",
    "Here, we convert two files from a previous publication by NiMARE contributors {cite:p}`yanes2018` into two separate `Dataset`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f9fc6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/runner/work/nimare-paper/nimare-paper/data/contrast-CannabisMinusControl_space-talairach_sleuth.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2188/888267057.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m sleuth_dset1 = nimare.io.convert_sleuth_to_dataset(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"contrast-CannabisMinusControl_space-talairach_sleuth.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m sleuth_dset2 = nimare.io.convert_sleuth_to_dataset(\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nimare/io.py\u001b[0m in \u001b[0;36mconvert_sleuth_to_dataset\u001b[0;34m(text_file, target)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unsupported type for parameter 'text_file': {type(text_file)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0mdset_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sleuth_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nimare/io.py\u001b[0m in \u001b[0;36mconvert_sleuth_to_dict\u001b[0;34m(text_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdset_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/runner/work/nimare-paper/nimare-paper/data/contrast-CannabisMinusControl_space-talairach_sleuth.txt'"
     ]
    }
   ],
   "source": [
    "from nimare import io\n",
    "\n",
    "sleuth_dset1 = nimare.io.convert_sleuth_to_dataset(\n",
    "    os.path.join(DATA_DIR, \"contrast-CannabisMinusControl_space-talairach_sleuth.txt\")\n",
    ")\n",
    "sleuth_dset2 = nimare.io.convert_sleuth_to_dataset(\n",
    "    os.path.join(DATA_DIR, \"contrast-ControlMinusCannabis_space-talairach_sleuth.txt\")\n",
    ")\n",
    "print(sleuth_dset1)\n",
    "print(sleuth_dset2)\n",
    "\n",
    "# Save the Datasets to files for future use\n",
    "if not os.path.isfile(os.path.join(DATA_DIR, \"sleuth_dset1.pkl.gz\")):\n",
    "    sleuth_dset1.save(os.path.join(DATA_DIR, \"sleuth_dset1.pkl.gz\"))\n",
    "\n",
    "if not os.path.isfile(os.path.join(DATA_DIR, \"sleuth_dset2.pkl.gz\")):\n",
    "    sleuth_dset2.save(os.path.join(DATA_DIR, \"sleuth_dset2.pkl.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6da83",
   "metadata": {},
   "source": [
    "## Neurosynth\n",
    "\n",
    "**Neurosynth** {cite:p}`Yarkoni2011-dk` uses a combination of web scraping and text mining to automatically harvest neuroimaging studies from the literature and to annotate them based on term frequency within article abstracts.\n",
    "As a consequence of its relatively crude automated approach, Neurosynth has its own set of limitations.\n",
    "First, Neurosynth is unable to delineate individual comparisons within studies, and consequently uses the entire paper as its unit of measurement, unlike BrainMap.\n",
    "This risks conflating directly contrasted comparisons (e.g., A>B and B>A), as well as comparisons which have no relation to one another.\n",
    "Second, coordinate extraction and annotation are noisy.\n",
    "Third, annotations automatically performed by Neurosynth are also subject to error, although the reasons behind this are more nuanced and will be discussed later in this paper.\n",
    "Given Neurosynth’s limitations, we recommend that it be used for casual, exploratory meta-analyses rather than for publication-quality analyses.\n",
    "Nevertheless, while individual meta-analyses should not be published from Neurosynth, many derivative analyses have been performed and published (e.g., {cite:p}`Chang2013-si,De_la_Vega2016-wg,De_la_Vega2018-jc,Poldrack2012-it`).\n",
    "As evidence of its utility, Neurosynth has been used to define _a priori_ regions of interest (e.g., {cite:p}`Josipovic2014-hx,Zeidman2012-fj,Wager2013-ab`) or perform meta-analytic functional decoding (e.g., {cite:p}`Chen2018-of,Pantelis2015-bq,Tambini2017-iu`) in many first-order (rather than meta-analytic) fMRI studies.\n",
    "\n",
    "Here, we download the Neurosynth database from where it is stored (https://github.com/neurosynth/neurosynth-data) and convert it to a NiMARE `Dataset` using {py:func}`nimare.extract.fetch_neurosynth`, for the first step, and {py:func}`nimare.io.convert_neurosynth_to_dataset`, for the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e15e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimare import extract\n",
    "\n",
    "# Download the desired version of Neurosynth from GitHub.\n",
    "files = extract.fetch_neurosynth(\n",
    "    data_dir=DATA_DIR,\n",
    "    version=\"7\",\n",
    "    source=\"abstract\",\n",
    "    vocab=\"terms\",\n",
    "    overwrite=False,\n",
    ")\n",
    "pprint(files)\n",
    "neurosynth_db = files[0]\n",
    "\n",
    "# Convert the files to a Dataset.\n",
    "# This may take a while (~10 minutes)\n",
    "neurosynth_dset = io.convert_neurosynth_to_dataset(\n",
    "    coordinates_file=neurosynth_db[\"coordinates\"],\n",
    "    metadata_file=neurosynth_db[\"metadata\"],\n",
    "    annotations_files=neurosynth_db[\"features\"],\n",
    ")\n",
    "print(neurosynth_dset)\n",
    "\n",
    "# Save the Dataset for later use.\n",
    "if not os.path.isfile(os.path.join(DATA_DIR, \"neurosynth_dataset.pkl.gz\")):\n",
    "    neurosynth_dset.save(os.path.join(DATA_DIR, \"neurosynth_dataset.pkl.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40a3ce",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Many of the methods in NiMARE can be very time-consuming or memory-intensive.\n",
    "Therefore, for the sake of ensuring that the analyses in this article may be reproduced by as many people as possible, we will use a reduced version of the Neurosynth Dataset, only containing the first 500 studies, for those methods which may not run easily on the full database.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61218423",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_dset_first_500 = neurosynth_dset.slice(neurosynth_dset.ids[:500])\n",
    "print(neurosynth_dset)\n",
    "\n",
    "if not os.path.isfile(os.path.join(DATA_DIR, \"neurosynth_dataset_first500.pkl.gz\")):\n",
    "    neurosynth_dset_first_500.save(os.path.join(DATA_DIR, \"neurosynth_dataset_first500.pkl.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae6f9b",
   "metadata": {},
   "source": [
    "In addition to a large corpus of coordinates, Neurosynth provides term frequencies derived from article abstracts that can be used as annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3949877a",
   "metadata": {},
   "source": [
    "One additional benefit to Neurosynth is that it has made available the coordinates for a large number of studies for which the study abstracts are also readily available.\n",
    "This has made the Neurosynth database a common resource upon which to build other automated ontologies.\n",
    "Data-driven ontologies which have been developed using the Neurosynth database include the generalized correspondence latent Dirichlet allocation (GCLDA) {cite:p}`Rubin2017-rd` topic model and Deep Boltzmann machines {cite:p}`Monti2016-aq`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341d83b",
   "metadata": {},
   "source": [
    "## NeuroQuery\n",
    "\n",
    "A related resource is **NeuroQuery** {cite:p}`Dockes2020-uv`.\n",
    "NeuroQuery is an online service for large-scale predictive meta-analysis.\n",
    "Unlike Neurosynth, which performs statistical inference and produces statistical maps, NeuroQuery is a supervised learning model and produces a prediction of the brain areas most likely to contain activations.\n",
    "These maps predict locations where studies investigating a given area (determined by the text prompt) are likely to produce activations, but they cannot be used in the same manner as statistical maps from a standard coordinate-based meta-analysis.\n",
    "In addition to this predictive meta-analytic tool, NeuroQuery also provides a new database of coordinates, text annotations, and metadata via an automated extraction approach that improves on Neurosynth's original methods.\n",
    "\n",
    "While NiMARE does not currently include an interface to NeuroQuery's predictive meta-analytic method, there are functions for downloading the NeuroQuery database and converting it to NiMARE format, much like Neurosynth.\n",
    "The functions for downloading the NeuroQuery database and converting it to a `Dataset` are {py:func}`nimare.extract.fetch_neuroquery` and {py:func}`nimare.io.convert_neurosynth_to_dataset`, respectively.\n",
    "We are able to use the same function for converting the database to a `Dataset` for NeuroQuery as Neurosynth because both databases store their data in the same structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the desired version of NeuroQuery from GitHub.\n",
    "files = extract.fetch_neuroquery(\n",
    "    data_dir=DATA_DIR,\n",
    "    version=\"1\",\n",
    "    source=\"combined\",\n",
    "    vocab=\"neuroquery6308\",\n",
    "    type=\"tfidf\",\n",
    "    overwrite=False,\n",
    ")\n",
    "pprint(files)\n",
    "neuroquery_db = files[0]\n",
    "\n",
    "# Convert the files to a Dataset.\n",
    "# This may take a while (~10 minutes)\n",
    "neuroquery_dset = io.convert_neurosynth_to_dataset(\n",
    "    coordinates_file=neuroquery_db[\"coordinates\"],\n",
    "    metadata_file=neuroquery_db[\"metadata\"],\n",
    "    annotations_files=neuroquery_db[\"features\"],\n",
    ")\n",
    "print(neuroquery_dset)\n",
    "\n",
    "# Save the Dataset for later use.\n",
    "if not os.path.isfile(os.path.join(DATA_DIR, \"neuroquery_dataset.pkl.gz\")):\n",
    "    neuroquery_dset.save(os.path.join(DATA_DIR, \"neuroquery_dataset.pkl.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d2eb6",
   "metadata": {},
   "source": [
    "## NeuroVault\n",
    "\n",
    "**NeuroVault** {cite:p}`Gorgolewski2015-sd` is a public repository of user-uploaded, whole-brain, unthresholded brain maps.\n",
    "Users may associate their image collections with publications, and can annotate individual maps with labels from the Cognitive Atlas, which is the ontology of choice for NeuroVault.\n",
    "NiMARE includes a function, {py:func}`nimare.io.convert_neurovault_to_dataset`, with which users can search for images in NeuroVault, download those images, and convert them into a `Dataset` object."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "source_map": [
   12,
   18,
   31,
   41,
   61,
   81,
   97,
   123,
   130,
   138,
   142,
   148,
   162,
   189
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}