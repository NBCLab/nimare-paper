{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6031c1",
   "metadata": {},
   "source": [
    "# Meta-Analytic Subtraction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4bca18",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/runner/work/nimare-paper/nimare-paper/data/sleuth_dset1.pkl.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2212/3080194871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Now, load the Datasets we will use in this chapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msleuth_dset1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnimare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sleuth_dset1.pkl.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0msleuth_dset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnimare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sleuth_dset2.pkl.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nimare/base.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, filename, compressed)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompressed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/runner/work/nimare-paper/nimare-paper/data/sleuth_dset1.pkl.gz'"
     ]
    }
   ],
   "source": [
    "# First, import the necessary modules and functions\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from myst_nb import glue\n",
    "from nilearn import image, plotting\n",
    "\n",
    "import nimare\n",
    "\n",
    "# Define where data files will be located\n",
    "DATA_DIR = os.path.abspath(\"../data\")\n",
    "FIG_DIR = os.path.abspath(\"../images\")\n",
    "\n",
    "# Now, load the Datasets we will use in this chapter\n",
    "sleuth_dset1 = nimare.dataset.Dataset.load(os.path.join(DATA_DIR, \"sleuth_dset1.pkl.gz\"))\n",
    "sleuth_dset2 = nimare.dataset.Dataset.load(os.path.join(DATA_DIR, \"sleuth_dset2.pkl.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f14a739",
   "metadata": {},
   "source": [
    "Subtraction analysis refers to the voxel-wise comparison of two meta-analytic samples.\n",
    "In image-based meta-analysis, comparisons between groups of maps can generally be accomplished within the standard meta-regression framework (i.e., by adding a covariate that codes for group membership).\n",
    "However, coordinate-based subtraction analysis requires special extensions for CBMA algorithms.\n",
    "\n",
    "Subtraction analysis to compare the results of two ALE meta-analyses was originally implemented by {cite:t}`Laird2005-qh` and later extended by {cite:t}`Eickhoff2012-hk`.\n",
    "In this approach, two groups of experiments (A and B) are compared using a group assignment randomization procedure in which voxel-wise null distributions are generated by randomly reassigning experiments between the two groups and calculating ALE-difference scores for each permutation.\n",
    "Real ALE-difference scores (i.e., the ALE values for one group minus the ALE values for the other) are compared against these null distributions to determine voxel-wise significance.\n",
    "In the original implementation of the algorithm, this procedure is performed separately for a group A > B contrast and a group B > A contrast, where each contrast is limited to voxels that were significant in the first group's original meta-analysis.\n",
    "\n",
    "In NiMARE, we use an adapted version of the subtraction analysis method in {py:class}`nimare.meta.cbma.ale.ALESubtraction`.\n",
    "Note that, unlike the original algorithm, the NiMARE implementation analyzes all voxels, rather than only those that show a significant effect of A alone or B alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bbb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimare import meta\n",
    "\n",
    "kern = meta.kernel.ALEKernel()\n",
    "sub_meta = meta.cbma.ale.ALESubtraction(kernel_transformer=kern, n_iters=10000)\n",
    "sub_results = sub_meta.fit(sleuth_dset1, sleuth_dset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6faae43",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 2))\n",
    "display = plotting.plot_stat_map(\n",
    "    sub_results.get_map(\"z_desc-group1MinusGroup2\", return_type=\"image\"),\n",
    "    annotate=False,\n",
    "    axes=ax,\n",
    "    cmap=\"RdBu_r\",\n",
    "    cut_coords=[0, 0, 0],\n",
    "    draw_cross=False,\n",
    "    figure=fig,\n",
    ")\n",
    "ax.set_title(\"ALE Subtraction\")\n",
    "\n",
    "colorbar = display._cbar\n",
    "colorbar_ticks = colorbar.get_ticks()\n",
    "if colorbar_ticks[0] < 0:\n",
    "    new_ticks = [colorbar_ticks[0], 0, colorbar_ticks[-1]]\n",
    "else:\n",
    "    new_ticks = [colorbar_ticks[0], colorbar_ticks[-1]]\n",
    "colorbar.set_ticks(new_ticks, update_ticks=True)\n",
    "glue(\"figure_subtraction\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5073ec03",
   "metadata": {},
   "source": [
    "```{glue:figure} figure_subtraction\n",
    ":figwidth: 150px\n",
    ":name: figure_subtraction\n",
    ":align: center\n",
    "\n",
    "An array of plots of the statistical maps produced by the meta-analysis.\n",
    "```\n",
    "\n",
    "Alternatively, MKDA Chi-squared analysis is inherently a subtraction analysis method, in that it compares foci from two groups of studies.\n",
    "Generally, one of these groups is a sample of interest, while the other is a meta-analytic database (minus the studies in the sample).\n",
    "With this setup, meta-analysts can infer whether there is greater convergence of foci in a voxel as compared to the baseline across the field (as estimated with the meta-analytic database), much like SCALE.\n",
    "However, if the database is replaced with a second sample of interest, the analysis ends up comparing convergence between the two groups."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "source_map": [
   12,
   18,
   38,
   52,
   60,
   82
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}